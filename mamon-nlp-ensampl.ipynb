{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#numpy for computionoial matrix  speed up\n",
    "#mat lap for ploting but we didin't used its yet in these  case\n",
    "#pandas to read the csv in effecint way\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>الخصخصة سرقه في وضح النهار من الشعب الكهرباء ملك الشعب وليس لحكومة والتجارة بها [[PHOTO]]</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>زين المليارات الي انصرفت عليها من سنة ???? لحد...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>إلى الجحيم وبئس المصير</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ولكم ذوله راح ينهبونه رسمي نهبو خيرات  االعراق...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>تعبونه  هولاء الحراميه</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>هههههه مي يمتة وداعش تفوق اضعاف قوة البيشمركة ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  الخصخصة سرقه في وضح النهار من الشعب الكهرباء ملك الشعب وليس لحكومة والتجارة بها [[PHOTO]]  \\\n",
       "0  زين المليارات الي انصرفت عليها من سنة ???? لحد...                                          \n",
       "1                             إلى الجحيم وبئس المصير                                          \n",
       "2  ولكم ذوله راح ينهبونه رسمي نهبو خيرات  االعراق...                                          \n",
       "3                             تعبونه  هولاء الحراميه                                          \n",
       "4  هههههه مي يمتة وداعش تفوق اضعاف قوة البيشمركة ...                                          \n",
       "\n",
       "     0  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coz your data is so messy we select only col 1 and 2   and we use tabe as delimiter\n",
    "dataSet = pd.read_csv('ALL.CSV')#,  sep='\\t' , quoting = 3 , usecols=[0,1])\n",
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#these  re use  regx we will use its to keep only arabic letter\n",
    "import re\n",
    "data = dataSet.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[11100,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#here is our preprocessing we take the data the coumint and we split each coumint into words\n",
    "#then we clean the word\n",
    "from stop_words import get_stop_words\n",
    "cs = []\n",
    "I , J = data.shape\n",
    "for i in xrange(I):\n",
    "    dx = str(data[i,0])\n",
    "    review = re.sub('[\\u0627-\\u064a]' ,' ' ,dx)\n",
    "    review = review.split()\n",
    "    stop_words1=[u'في',u'مثل',u'هاي',u'هذا',u'من',u'ابو',u'مع',u'هم',u'بيهم',u'اللخ',u'هو',u'?']\n",
    "#get_stop_words('ar')\n",
    "    stop_words2 = get_stop_words('ar')\n",
    "    stop_words = stop_words1 + stop_words2\n",
    "    #these loop remove the stopword from the coumit you can replcat its to make also stem phase\n",
    "    review = [word for word in review if not unicode(word, encoding='utf-8') in stop_words  ]\n",
    "    review = ' '.join(review)\n",
    "    cs.append(review)\n",
    "#here we do spars matrix  in these we enforce as max 1400 col\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 2100)\n",
    "X = cv.fit_transform(cs).toarray()\n",
    "y = dataSet.iloc[:, 1].values\n",
    "\n",
    "for i in xrange(len(y)):\n",
    "    if np.isnan(y[i]):\n",
    "        y[i] = 1\n",
    "        print 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11994, 2100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xd8\\xb2\\xd9\\x8a\\xd9\\x86 \\xd8\\xa7\\xd9\\x84\\xd9\\x85\\xd9\\x84\\xd9\\x8a\\xd8\\xa7\\xd8\\xb1\\xd8\\xa7\\xd8\\xaa \\xd8\\xa7\\xd9\\x84\\xd9\\x8a \\xd8\\xa7\\xd9\\x86\\xd8\\xb5\\xd8\\xb1\\xd9\\x81\\xd8\\xaa \\xd8\\xb9\\xd9\\x84\\xd9\\x8a\\xd9\\x87\\xd8\\xa7 \\xd9\\x85\\xd9\\x86 \\xd8\\xb3\\xd9\\x86\\xd8\\xa9 ???? \\xd9\\x84\\xd8\\xad\\xd8\\xaf ???? \\xd9\\x88\\xd9\\x8a\\xd9\\x86\\xd9\\x87\\xd8\\xa7 \\xd9\\x87\\xd8\\xb0\\xd9\\x86\\xd9\\x8a\\xd8\\xac \\xd9\\x86\\xd8\\xb2\\xd9\\x84\\xd8\\xaa\\xd9\\x88\\xd9\\x87\\xd8\\xa7 \\xd8\\xa8\\xd8\\xac\\xd9\\x8a\\xd8\\xa8\\xd9\\x88\\xd9\\x83\\xd9\\x85 \\xd9\\x83\\xd9\\x84\\xd9\\x83\\xd9\\x85 \\xd8\\xad\\xd8\\xb1\\xd8\\xa7\\xd9\\x85\\xd9\\x8a\\xd9\\x87 \\xd9\\x88\\xd9\\x84\\xd8\\xa7 \\xd9\\x88\\xd8\\xa7\\xd8\\xad\\xd8\\xaf \\xd8\\xb4\\xd8\\xb1\\xd9\\x8a\\xd9\\x81 \\xd8\\xa8\\xd9\\x8a\\xd9\\x83\\xd9\\x85'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "سارق اموال النازحين\n"
     ]
    }
   ],
   "source": [
    "print unicode(cs[11], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "سارق اموال النازحين\n"
     ]
    }
   ],
   "source": [
    "print unicode(data[11,0], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print X[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split data for training and test  but in our case its so bad to do so coz we have very very litile data\n",
    "#please increase the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gradaint boost treee is learning like neural networks\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifier = GradientBoostingClassifier(n_estimators=500, learning_rate=1.0,max_depth=5, random_state=0, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#adaboost  bosted ensamble learning\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "classifier = AdaBoostClassifier(n_estimators=500)\n",
    "                                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "classifier = classifier.fit(X_train , y_train)\n",
    "scores = cross_val_score(classifier, X_train , y_train, cv=5)\n",
    "print scores\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#التصنيف بتقنية التصويت  مطولة ولكن  مفيدة\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf0 = AdaBoostClassifier(n_estimators=300)\n",
    "\n",
    "# Training classifiers\n",
    "clf1 = DecisionTreeClassifier(max_depth=36)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=12)\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "clf4 = GaussianNB()\n",
    "classifier = VotingClassifier(estimators=[('ada',clf0),('dt', clf1), ('knn', clf2), ('svc', clf3) ,('navia' , clf4)], voting='soft',n_jobs=-1, weights=[3,2,2,1,1])\n",
    "\n",
    "\n",
    "classifier = classifier.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  1., ...,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1874,  141],\n",
       "       [ 292, 1292]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getscore(orgin , predicted):\n",
    "    score = 0\n",
    "    print orgin.shape\n",
    "    #print score\n",
    "    j = 0\n",
    "    for i in predicted:\n",
    "        if i == orgin[j]:\n",
    "            score +=1\n",
    "            j +=1\n",
    "        else:\n",
    "            #score -=1\n",
    "            j +=1\n",
    "    print score\n",
    "    result = (score / float(orgin.shape[0]) ) * 100.00000\n",
    "    result = str(result)\n",
    "    return result+'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3599,)\n",
      "3166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'87.9688802445%'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getscore(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.879688802445\n"
     ]
    }
   ],
   "source": [
    "SCORS = np.mean(y_test == y_pred)\n",
    "print SCORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
